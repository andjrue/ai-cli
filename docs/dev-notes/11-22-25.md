# Overview

So far, this project has gone surprisingly smoothly. The UI looks great, we're able to pull in different models when needed, etc. tview has been a lot easier to use that bubbletea, so I think I made a good choice there.

The main functionality of the app is in place. We can type into the terminal, send the request to an LLM, and stream a response back. 

## Up Next
Next up is adding more models and testing with those. Should be simple enough, I'll know if its working when I ask the model which one they are. I'll also be able to see metrics in each providers dashboard.

I also want to refactor the UI a bit. Breaking things out into components has been great and something I'll continue to do. I also want to add a few commands to enable scrolling in the window, and for focusing different windows. This will be particularly important when we have saved chats.

One more thing, I want to pass in conversational context to the LLM. This will be easier to do when we write everything into either the main config file, or a separate JSON we store that has who sent the message, what it contains, etc. It should also be sorted by timestamp.

I also need to add a system prompt. This should be configurable in the yaml file so that users of this can give models whatever personality or instructions they want. 

### TODOs

- [X] Add new models
- [] Continue UI refactor
- [] Add conversation storage
- [] Pass in context from the conversation
- [] Add a system prompt